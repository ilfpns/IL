## 1. RAM의 특징과 종류
[[OS]]
- ROM
    
    한번 기록한 데이터를 다시 기록할 수 없다는 단점이 크게 작용하여, 현대 사회에 사용률이 떨어짐
    
    전원 차단 후에도 데이터를 유지하며, Read-Only 특성을 가지기 때문에 펌웨어나 BIOS에서 사용됨
    
- RAM
    

⇒ 실행할 프로그램 명령어와 데이터가 저장된다

⇒ 휘발성 메모리로, 실행될 대상을 저장한다

- RAM의 크기가 큰 만큼 많은 양의 프로세스를 보조 기억장치에서 많이 가져오므로 빨라짐
    
    RAM의 용량이 커지는만큼 실행 속도가 비례해 커지는 것은 아니다
    

### 1.1 RAM의 종류

1. DRAM
    - 시간이 지남에 따라 데이터가 사라진다
2. SRAM
    - 시간이 지나도 데이터가 저장된다
    - DRAM에 비해 속도가 빠르다
3. DDR SDRAM
    - Double Data Rate로 대역폭을 넓혀 속도를 빠르게 만든 SDRAM이다
    - SDRAM보다 대역폭이 2배 넓기 때문에 한 클럭에 2번씩 CPU와 데이터를 주고받을 수 있다
    - DDR2는 DDR 대역폭의 2배를 의미한다

## 2. 메모리 주소 공간

프로세스는 2가지 주소를 가진다

- 물리 주소 (Physical Address)
- 논리 주소 (Logical Address)

<aside>

EX)

- Chrome, game, note 3개의 프로세스가 돌아감
    
- 각자 다음과 같은 논리 주소를 가짐
    
- Chrome : 0 ~ 7 번지
    
- Game : 0 ~ 2 번지
    
- Note : 0 ~ 3 번지 </aside>
    

이러한 가상 주소들은 물리 주소와 대응되어야 한다

⇒ CPU와 주소 버스 사이에 MMU 위치

### 2.1 MMU

⇒ 논리 주소를 물리 주소로 변환함

⇒ 메모리 보호 및 캐시 관리 등 CPU가 메모리에 접근하는 것을 총 관리한다

왜 사용하는가?

- 메모리 공간은 한정적이다
    
    CPU가 저장공간보다 큰 프로세스를 실행하려 하는데, RAM이 부족하다면
    
    - 실제로는 실행할 데이터만 RAM에서 돌아가고, 나머지는 디스크로 내려감
    - CPU는 프로세스 전체를 한번에 적재할 메모리가 (가상 메모리) 있다고 생각함

⇒ 빠른 접근을 위한 주소 변환에 사용됨

### 2.2 TLB

기존 CPU

1. Page Table에 접근
2. Page Table을 기반으로 실제 메모리 접근

⇒ 2번의 메모리 접근

TLB

⇒ 최근에 읽었던 Page Table을 매핑하여 저장함

- 굉장히 작은 크기이다

### 2.3 Over Allocation (메모리 과할당)

⇒ 실제 메모리의 사이즈보더 더 큰 사이즈의 메모리를 프로세스에 할당한 상황

상황

- RAM : 16GB
- Chrome : 8GB
- Game : 8GB
- note : 8GB

⇒ 램은 16GB인 상황에서 OS는 24GB 지급을 약속했다

⇒ 이런 상황에서 PC가 잘 돌아가는 이유는

⇒ 프로세스들이 요청한 메모리를 한꺼번에 다 쓰지 않기 때문이다

- 이를 Swapping이라 한다
    
    현재 실쟁 중인 프로세스의 일부만 메모리에 올리고, 나머지 프로세스는 보조 저장 장치에 Swap out하여 저장하는 방식
    

### 2.4 메모리 보호 기법

가정

- Chrome : 1000 ~ 1999
- Game : 2000 ~ 2999

각 프로세스가 물리주소를 다음과 같이 가질 때

“Chrome의 논리주소 1350번지에 X이걸 적어!” 라는 명령은 실행될 수 없다.

⇒ Chrome의 논리죽소는 0 ~ 999 이기 때문에

이러한 문제를 방지하기 위해 한계 레지스터가 존재한다

### 2.5 Limit Register

⇒ 베이스 레지스터에 실행 중인 프로그램의 가장 작은 물리 주소가 저장된다면, 한계 레지스터에는 논리 주소의 최대 크기를 저장한다

- Chrome의 베이스 레지스터 : 1000
    
- Chrome의 한계 레지스터 : 1000
    
- Game의 베이스 레지스터 : 2000
    
- Game의 한계 레지스터 : 1000 (프로세스의 전체 크기)
    

⇒ 접근하려는 논리 주소가 프로세스의 한계 레지스터보다 작다면 인터럽트를 발생시킨다

## 3. 캐시 메모리

⇒ CPU가 메모리에 접근하는 속도가 느리기 때문에 컴퓨터에서 사용도되는 메모리

- CPU와 메모리 사이에 위치한다
- SRAM 기반의 저장 장치이다

L1, L2, L3

- L1
    
    접근 속도를 조금이라도 빠르게 하기 위해
    
    명령어 캐시와 데이터 캐시를 분리할 수도 있다
    
    ⇒ 분리형 캐시
    
    - L1l : 명령어 저장
    - L1D : 데이터 저장
- CPU내부 : L1, L2
    
- CPU외부 : L3
    

### 3.1 참조 지역성 원리

캐시 메모리의 크기는 메모리보다 작기 때문에 적은 양을 저장할 수 있다

⇒ CPU가 사용합 법한 대상을 예측하여 저장해야 한다

해당 데이터가

- 사용될 경우 : Cache Hit
- 사용되지 않을 경우 : Cache Miss

Cache HIt가 발생하는 캐시 적중율을 Cache Hit Ratio라고 한다

$$ 캐시 히트 횟수 / 캐시 히트 횟수 + (캐시 미스 횟수) $$

⇒ 어떻게 예측할까?

CPU가 가진 2개의 특성을 기반으로 예측한다

1. CPU는 최근에 접근한 메모리에 다시 접근하려는 경향이 있다
2. CPU는 접근한 메모리 공간 근처를 접근하려는 경향이 있다

왜 1번과 같은 경향을 보일까

- 값을 변수에 저장하면 CPU는 이 때 해당 값을 다시 사용한다고 인식함
- 변수 할당은 편하게, 다시 사용하기 위함이기 때문에 CPU는 이 의도를 파악

⇒ 최근 접근한 메모리를 다시 접근하려는 경향을 시간 지역성이라고 부른다

왜 2번과 같은 경향을 보일까

- CPU는 Chrome이 실행하는 데에 관련 데이터끼리 모아서 저장한다
- CPU가 Chrome 프로그램을 사용할 때 Chrome 프로그램 근처를 집중적으로 접근

⇒ 접근한 메모리 근처를 접근하려는 경향을 공간 지역성이라고 부른다

### 3.2 Page Cache

⇒ CPU는 기본적으로 사용을 적게 할수록 발열이 낮아져 성능이 좋아진다, 하지만 메모리는 사용량에 따라 속도가 바뀌지 않는다

- 메인 메모리 (RAM)에 남는 공간을 활용해 Page Cache라는 공간을 마련한다
- 필요에 따라 늘어나고, 메모리가 부족하면 줄어드는 동적 영역이다

### **3.3 Page Cache와 Page Table**

- Page Table : 가상주소에 대응되는 물리주소를 가짐
    
    프로세스가 사용하는 가상 주소를 실제 RAM 물리 주소로 변환
    
- Page Cache : 디스크 I/O를 줄임
    
    디스크에서 최근 읽은 파일 데이터를 RAM에 저장해 두는 캐시
    

**상황**

<aside>

1. read 호출
2. VFS 호출
3. Page Cache 확인
    - 주소가 있다면 : RAM에서 반환 (Cache hit)
    - 주소가 없다면 : 디스크를 읽고 Page Cache에 저장 후 반환 (Cache Miss) </aside>

<aside>

1. write 호출
2. Page Cache에 기록
3. 이후 writeback thread (커널 내부 백그라운드 커널 스레드)가 디스크로 flush

⇒ Write back 방식 사용

⇒ Flush ⇒ Cache에 dirty상태의 값을 디스크에 저장하는 것

</aside>

- write-back
    
    RAM (Page Cache)에 먼저 쓰고, 나중에 디스크로 Flush
    
- write-through
    
    write하는 즉시 디스크에도 기록
    
- Dirty
    
    RAM에는 수정이 반영되었지만, Disk에는 적용되지 않았음
    
- Offset
    
    ```c
    HELLO WORLD
    byte 0        byte 4095 | byte 4096        byte 8191 | byte 8192 ...
    |----------------------|-------------------------------|----------
          page 0                 page 1                      page 2
    
    ```
    
    |문자|오프셋|
    |---|---|
    |H|0|
    |E|1|
    |L|2|
    |O|4|
    

### 3.3 Cache line

⇒ 캐시에 데이터가 저장될 때, 묶이는 기본적 단위

⇒ CPU가 캐시 메모리에서 목적 데이터를 바로 접근하기 위해 만들어짐

⇒ CPU가 RAM까지 가지 않고 바로 L1캐시에서 데이터를 읽을 수 있도록 함

Cache와 RAM의 매칭 방식

- Direct Mapping
    
    - RAM을 일정한 크기로 나눠, 각 블록을 정해진 캐시로 옮긴다
    - 구현이 쉽지만, 동일한 캐시 메모리 위치로 mapping된 데이터는 충돌을 발생시킨다
- Full Associative Mapping
    
    - 캐시 빈 공간에 임의로 주소를 저장한다
    - 저장이 쉽지만, 데이터 탐색이 어렵다
- Set Assicuactive Mapping
    
    - Direct Mapping과 Full Associative Mapping의 장점을 결합한 방식으로, 빈 공간에 임의로 주소를 저장하되, 미리 정해둔 특정 행에만 저장한다

### 4. Register

⇒ 고속 연산 장치

순서

- PC (Program Counter) : 다음에 실행할 코드 주소 저장
- IR (Instruction Register) : 현재 실행중인 코드 주소 저장

배달

- MAR (Memory Address Register) : read/write할 RAM의 주소값을 저장
    
    ⇒ 주소 버스와 연결됨
    
- MBR (Memory Buffer Register) : 메모리에서 읽어온 데이터 혹은 쓸 데이터 저장
    
    ⇒ 데이터 버스와 연결됨
    
- Flow : MAR이 주소를 지정하면 해당 주소에 있는 값이 버스를 타고 MBR로 들어온다
    

계산

- AC (Accumulator) : 실제 계산을 수행한다
- Status Register : 연산 결과의 상태 정보를 비트 단위로 저장한다

### 5. 메모리 단편화

⇒ RAM에서 메모리의 공간이 작은 조각으로 나뉘어져, 사용 가능한 메모리는 충분하지만, 할당이 불가한 상태

### 5.1 내부 단편화

⇒ Over allocation이 원인으로, 프로세스가 요구한 크기보다 큰 메모리가 할당됨

- 프로세스는 1KB가 필요함
- OS는 기본적으로 4KB를 할당함

⇒ Over allocation

### 5.2 내부 단편화

⇒ 메모리 할당 & 해제가 반복될 때

- 순차적으로 8KB, 16KB 메모리가 할당됨
- 8KB 메모리가 해제됨
- 9KB 메모리를 할당할 때 이전에 할당한 8KB 메모리를 다시 사용하지 않으므로

⇒ 메모리 구멍

|**구분**|**내부 단편화 (Internal)**|**외부 단편화 (External)**|
|---|---|---|
|**위치**|할당된 영역 **안쪽**|할당된 영역 **바깥쪽** (각 프로세스 사이에)|
|**원인**|메모리를 **고정 크기**로 줄 때|메모리를 **가변 크기**로 줬다가 뺏을 때|
|**해결**|Slab Allocator|페이징, 조각 모음|

Paging

Compaction