## 1. RAM의 특징과 종류 [[OS]]

- ROM
    
    한번 기록한 데이터를 다시 기록할 수 없다는 단점이 크게 작용하여, 현대 사회에 사용률이 떨어짐
    
    전원 차단 후에도 데이터를 유지하며, Read-Only 특성을 가지기 때문에 펌웨어나 BIOS에서 사용됨
    
- RAM
    

⇒ 실행할 프로그램 명령어와 데이터가 저장된다

⇒ 휘발성 메모리로, 실행될 대상을 저장한다

- RAM의 크기가 큰 만큼 많은 양의 프로세스를 보조 기억장치에서 많이 가져오므로 빨라짐
    
    RAM의 용량이 커지는만큼 실행 속도가 비례해 커지는 것은 아니다
    

### 1.1 RAM의 종류

1. DRAM
    - 시간이 지남에 따라 데이터가 사라진다
2. SRAM
    - 시간이 지나도 데이터가 저장된다
    - DRAM에 비해 속도가 빠르다
3. DDR SDRAM
    - Double Data Rate로 대역폭을 넓혀 속도를 빠르게 만든 SDRAM이다
    - SDRAM보다 대역폭이 2배 넓기 때문에 한 클럭에 2번씩 CPU와 데이터를 주고받을 수 있다
    - DDR2는 DDR 대역폭의 2배를 의미한다

## 2. 메모리 주소 공간

프로세스는 2가지 주소를 가진다

- 물리 주소 (Physical Address)
- 논리 주소 (Logical Address)

<aside>

EX)

- Chrome, game, note 3개의 프로세스가 돌아감
    
- 각자 다음과 같은 논리 주소를 가짐
    
- Chrome : 0 ~ 7 번지
    
- Game : 0 ~ 2 번지
    
- Note : 0 ~ 3 번지 </aside>
    

이러한 가상 주소들은 물리 주소와 대응되어야 한다

⇒ CPU와 주소 버스 사이에 MMU 위치

### 2.1 MMU

⇒ 논리 주소를 물리 주소로 변환함

⇒ 메모리 보호 및 캐시 관리 등 CPU가 메모리에 접근하는 것을 총 관리한다

왜 사용하는가?

- 메모리 공간은 한정적이다
    
    CPU가 저장공간보다 큰 프로세스를 실행하려 하는데, RAM이 부족하다면
    
    - 실제로는 실행할 데이터만 RAM에서 돌아가고, 나머지는 디스크로 내려감
    - CPU는 프로세스 전체를 한번에 적재할 메모리가 (가상 메모리) 있다고 생각함

⇒ 빠른 접근을 위한 주소 변환에 사용됨

### 2.2 TLB

기존 CPU

1. Page Table에 접근
2. Page Table을 기반으로 실제 메모리 접근

⇒ 2번의 메모리 접근

TLB

⇒ 최근에 읽었던 Page Table을 매핑하여 저장함

- 굉장히 작은 크기이다

### 2.3 Over Allocation (메모리 과할당)

⇒ 실제 메모리의 사이즈보더 더 큰 사이즈의 메모리를 프로세스에 할당한 상황

상황

- RAM : 16GB
- Chrome : 8GB
- Game : 8GB
- note : 8GB

⇒ 램은 16GB인 상황에서 OS는 24GB 지급을 약속했다

⇒ 이런 상황에서 PC가 잘 돌아가는 이유는

⇒ 프로세스들이 요청한 메모리를 한꺼번에 다 쓰지 않기 때문이다

- 이를 Swapping이라 한다
    
    현재 실쟁 중인 프로세스의 일부만 메모리에 올리고, 나머지 프로세스는 보조 저장 장치에 Swap out하여 저장하는 방식
    

### 2.4 메모리 보호 기법

가정

- Chrome : 1000 ~ 1999
- Game : 2000 ~ 2999

각 프로세스가 물리주소를 다음과 같이 가질 때

“Chrome의 논리주소 1350번지에 X이걸 적어!” 라는 명령은 실행될 수 없다.

⇒ Chrome의 논리죽소는 0 ~ 999 이기 때문에

이러한 문제를 방지하기 위해 한계 레지스터가 존재한다

### 2.5 Limit Register

⇒ 베이스 레지스터에 실행 중인 프로그램의 가장 작은 물리 주소가 저장된다면, 한계 레지스터에는 논리 주소의 최대 크기를 저장한다

- Chrome의 베이스 레지스터 : 1000
    
- Chrome의 한계 레지스터 : 1000
    
- Game의 베이스 레지스터 : 2000
    
- Game의 한계 레지스터 : 1000 (프로세스의 전체 크기)
    

⇒ 접근하려는 논리 주소가 프로세스의 한계 레지스터보다 작다면 인터럽트를 발생시킨다

## 3. 캐시 메모리

⇒ CPU가 메모리에 접근하는 속도가 느리기 때문에 컴퓨터에서 사용도되는 메모리

- CPU와 메모리 사이에 위치한다
- SRAM 기반의 저장 장치이다

L1, L2, L3

- L1
    
    접근 속도를 조금이라도 빠르게 하기 위해
    
    명령어 캐시와 데이터 캐시를 분리할 수도 있다
    
    ⇒ 분리형 캐시
    
    - L1l : 명령어 저장
    - L1D : 데이터 저장
- CPU내부 : L1, L2
    
- CPU외부 : L3
    

### 3.1 참조 지역성 원리

캐시 메모리의 크기는 메모리보다 작기 때문에 적은 양을 저장할 수 있다

⇒ CPU가 사용합 법한 대상을 예측하여 저장해야 한다

해당 데이터가

- 사용될 경우 : Cache Hit
- 사용되지 않을 경우 : Cache Miss

Cache HIt가 발생하는 캐시 적중율을 Cache Hit Ratio라고 한다

$$ 캐시 히트 횟수 / 캐시 히트 횟수 + (캐시 미스 횟수) $$

⇒ 어떻게 예측할까?

CPU가 가진 2개의 특성을 기반으로 예측한다

1. CPU는 최근에 접근한 메모리에 다시 접근하려는 경향이 있다
2. CPU는 접근한 메모리 공간 근처를 접근하려는 경향이 있다

왜 1번과 같은 경향을 보일까

- 값을 변수에 저장하면 CPU는 이 때 해당 값을 다시 사용한다고 인식함
- 변수 할당은 편하게, 다시 사용하기 위함이기 때문에 CPU는 이 의도를 파악

⇒ 최근 접근한 메모리를 다시 접근하려는 경향을 시간 지역성이라고 부른다

왜 2번과 같은 경향을 보일까

- CPU는 Chrome이 실행하는 데에 관련 데이터끼리 모아서 저장한다
- CPU가 Chrome 프로그램을 사용할 때 Chrome 프로그램 근처를 집중적으로 접근

⇒ 접근한 메모리 근처를 접근하려는 경향을 공간 지역성이라고 부른다

### 3.2 Page Cache

⇒ CPU는 기본적으로 사용을 적게 할수록 발열이 낮아져 성능이 좋아진다, 하지만 메모리는 사용량에 따라 속도가 바뀌지 않는다

- 메인 메모리 (RAM)에 남는 공간을 활용해 Page Cache라는 공간을 마련한다
- 필요에 따라 늘어나고, 메모리가 부족하면 줄어드는 동적 영역이다

### **3.3 Page Cache와 Page Table**

- Page Table : 가상주소에 대응되는 물리주소를 가짐
    
    프로세스가 사용하는 가상 주소를 실제 RAM 물리 주소로 변환
    
    - Page Table과 MMU
        
        1. CPU가 원하는 논리 주소를 MMU에게 명령
        2. MMU는 RAM에 위치한 Page Table에 접근
        3. 논리 주소에 대응하는 물리 주소 검색
        4. RAM에 접근하여 대응된 물리 주소로 검색
        5. 데이터 확보
        
        - TLB
            
            TLB는 MMU안에 위치하여, 매번 RAM까지 방문할 필요가 없도록 함
            
- Page Cache : 디스크 I/O를 줄임
    
    디스크에서 최근 읽은 파일 데이터를 RAM에 저장해 두는 캐시
    

**상황**

<aside>

1. read 호출
2. VFS 호출
3. Page Cache 확인
    - 주소가 있다면 : RAM에서 반환 (Cache hit)
    - 주소가 없다면 : 디스크를 읽고 Page Cache에 저장 후 반환 (Cache Miss) </aside>

<aside>

1. write 호출
2. Page Cache에 기록
3. 이후 writeback thread (커널 내부 백그라운드 커널 스레드)가 디스크로 flush

⇒ Write back 방식 사용

⇒ Flush ⇒ Cache에 dirty상태의 값을 디스크에 저장하는 것

</aside>

- write-back
    
    RAM (Page Cache)에 먼저 쓰고, 나중에 디스크로 Flush
    
- write-through
    
    write하는 즉시 디스크에도 기록
    
- Dirty
    
    RAM에는 수정이 반영되었지만, Disk에는 적용되지 않았음
    
- Offset
    
    ```c
    HELLO WORLD
    byte 0        byte 4095 | byte 4096        byte 8191 | byte 8192 ...
    |----------------------|-------------------------------|----------
          page 0                 page 1                      page 2
    
    ```
    
    |문자|오프셋|
    |---|---|
    |H|0|
    |E|1|
    |L|2|
    |O|4|
    

### 3.3 Cache line

⇒ 캐시에 데이터가 저장될 때, 묶이는 기본적 단위

⇒ CPU가 캐시 메모리에서 목적 데이터를 바로 접근하기 위해 만들어짐

⇒ CPU가 RAM까지 가지 않고 바로 L1캐시에서 데이터를 읽을 수 있도록 함

Cache와 RAM의 매칭 방식

- Direct Mapping
    
    - RAM을 일정한 크기로 나눠, 각 블록을 정해진 캐시로 옮긴다
    - 구현이 쉽지만, 동일한 캐시 메모리 위치로 mapping된 데이터는 충돌을 발생시킨다
- Full Associative Mapping
    
    - 캐시 빈 공간에 임의로 주소를 저장한다
    - 저장이 쉽지만, 데이터 탐색이 어렵다
- Set Assicuactive Mapping
    
    - Direct Mapping과 Full Associative Mapping의 장점을 결합한 방식으로, 빈 공간에 임의로 주소를 저장하되, 미리 정해둔 특정 행에만 저장한다

### 4. Register

⇒ 고속 연산 장치

순서

- PC (Program Counter) : 다음에 실행할 코드 주소 저장
- IR (Instruction Register) : 현재 실행중인 코드 주소 저장

배달

- MAR (Memory Address Register) : read/write할 RAM의 주소값을 저장
    
    ⇒ 주소 버스와 연결됨
    
- MBR (Memory Buffer Register) : 메모리에서 읽어온 데이터 혹은 쓸 데이터 저장
    
    ⇒ 데이터 버스와 연결됨
    
- Flow : MAR이 주소를 지정하면 해당 주소에 있는 값이 버스를 타고 MBR로 들어온다
    

계산

- AC (Accumulator) : 실제 계산을 수행한다
- Status Register : 연산 결과의 상태 정보를 비트 단위로 저장한다

### 5. 메모리 단편화

⇒ RAM에서 메모리의 공간이 작은 조각으로 나뉘어져, 사용 가능한 메모리는 충분하지만, 할당이 불가한 상태

### 5.1 내부 단편화

⇒ Over allocation이 원인으로, 프로세스가 요구한 크기보다 큰 메모리가 할당됨

- 프로세스는 1KB가 필요함
- OS는 기본적으로 4KB를 할당함

⇒ Over allocation

### 5.2 내부 단편화

⇒ 메모리 할당 & 해제가 반복될 때

- 순차적으로 8KB, 16KB 메모리가 할당됨
- 8KB 메모리가 해제됨
- 9KB 메모리를 할당할 때 이전에 할당한 8KB 메모리를 다시 사용하지 않으므로

⇒ 메모리 구멍

|**구분**|**내부 단편화 (Internal)**|**외부 단편화 (External)**|
|---|---|---|
|**위치**|할당된 영역 **안쪽**|할당된 영역 **바깥쪽** (각 프로세스 사이에)|
|**원인**|메모리를 **고정 크기**로 줄 때|메모리를 **가변 크기**로 줬다가 뺏을 때|
|**해결**|Slab Allocator|페이징, 조각 모음|

Paging

⇒ 메모리 공간을 작게 나누어서 비연속적으로 실제 메모리에 할당하는 메모리 관리 기법

**요구사항**

- 메모리가 어디에 할당되었는지 빠르게 알 수 있어야 한다
- MMU로 논리, 물리 간 주소 변환 가능하게 해야한다

다음과 같이 할당되며

- 프로세스는 Virtual Page Number를 보고, 메모리가 연속적이다고 판단
- 실제로는 논리주소에 대응하는 Physical Frame Number가 있

|Virtual Page Number|Physical Frame Number|
|---|---|
|0x00000|12|
|0x00001|7|
|0x00002|3|
|0x00003|25|
|0x00004|2|

Compaction

⇒ 메모리를 압축하는 방식으로 크게 2가지로 나뉜다

- Sliding
    
    ⇒ 사용할 수 있는 메모리를 모두 한쪽 끝으로 몰아 넣는다
    
    - 장점 : 추가 메모리 요구 없이 진행된다
        
    - 단점 : 전체 메모리가 이동하기 때문에, stop-the-world 시간이 길어진다
        
    - stop-the-world
        
        애플리케이션의 모든 스레드가 멈추는 시간
        
    
    ```c
    Before:
    [A][ ][B][ ][C][ ][ ]
    
    After:
    [A][B][C][ ][ ][ ][ ]
    ```
    
- Copying Compaction
    
    ⇒ 살아있는 객체는 다른 영역으로 복사하고, 기존 영역은 버린다
    
    - 장점 : 빠른 시간에 이뤄지고, 구현이 쉽다
    - 단점 : 사용할 수 있는 실제 공간이 줄어든다, 오래 사는 객체는 의미없는 복사 과정이 반복된다

```c
From-space:
[A][ ][B][ ][C][ ][ ]

To-space:
[ ][ ][ ][ ][ ][ ][ ]

- A, B, C를 복사 후 To-space로 이동
- From-space 삭제
```

## 6. Thrashing

사전 지식

프로세스 수가 많아질 때 어느 한계점 까지는 CPU이용율이 증가하다가 어느 한계점 이상부터 CPU이용율이 떨어짐

⇒ 이유 중 하나가 스레싱 때문이다

### 6.1 스레싱

⇒ Page fault가 증가하여 CPU이용율이 급격하게 떨어지는 현상

⇒ CPU이용율이 떨어지고, 페이지 교체만 일어나는 상황

**발생 이유**

⇒ 프로세스 실행 시 필요한 페이지가 RAM에 있어야 하는데, 프로세스가 너무 많을 경우 RAM에 페이지가 없다

⇒ 해당 경우는 Page fault를 일으킴

악순환

1. 스레싱이 일어남
2. Page Fault가 CPU연산보다 많이 일어남
3. CPU에 부하가 줄어듦
4. CPU에 일이 줄어들었다고 판단하여 프로세스를 RAM에 더 오림
5. Page Fault가 계속해서 발생함
6. 악순환 반복

### 6.2 Working set

⇒ 어떤 프로세스가 최근 일정 시간 동안 실제로 사용한 페이지의 집합

상황

```c
각 프로세스 working set 크기 합 > 물리 RAM크기
```

다음과 같은 경우일 때

- 일부 프로세스를 메모리에서 내린다
- MPD를 줄인다
- 남은 프로세스에 충분한 프레임 할당

## 7. 메모리 할당

⇒ 메모리 할당에 대해 조금 더 자세히 다룬다

### 7.1 페이징 Paging

⇒ 프로세스의 메모리 공간을 동일한 크기의 page로 나누어 물리적 메모리의 서로 다른 위치에 page들을 저장하는 메모리 관리 기법

⇒ Paging을 진행할 때 프로세스를 나눈 단위 (Page)와 RAM을 나눈 단위 (Frame)은 같다

- Page, Frame
    
    - Page : 프로세스를 나누는 크기 단위
    - Frame : 물리 메모리를 나누는 크기 단위
    
    ⇒ Page의 단위와 Frame의 크기는 같다
    

**단편화**

- 외부
    
    ⇒ 메모리가 불규칙적으로 흩어져 있어도, Page는 Frame과 같기 때문에 흩어진 메모리를 Page로 채움
    
- 내부
    
    ⇒ Page 다음과 같이 일정하지 않기 때문에 내부 단편화를 막을 수 없음
    
    ```c
    [4][4][4][4][2]
    마지막 Page는 Page(=Frame)의 최대 크기를 채우지 못함
    => 2KB가 단편화로 이어짐
    ```
    

![image.png](attachment:5dd6f16b-1595-4173-96dd-9dea75a5929e:image.png)

### 7.2 세그멘테이션 Segmentation

⇒ 프로세스가 할당받은 메모리 공간을 논리적 의미 단위 (segment)로 나누어, 연속되지 않는 물리 메모리 공간에 할당하는 메모리 관리 기법

슬라이싱

- 코드 (code) 세그먼트 : 명령어 (150KB)
- 데이터 (data) 세그먼트 : 전역 변수 (50KB)
- 스택 (Stack) 세그먼트 : 지역 변수 및 함수 (200KB)

다음과 같이 Paging은 의미나 위치를 구분하지 않고 크기만 기준으로 삼아 자르는 반면,

세그먼테이션은 용도가 명확한, 의미 단위로 나눈다

장점

- 보안
    
    <aside>
    
    페이징은 한 공간 안에 여러 데이터가 마구 섞여있다, 하여 한 영역을 보호할 수 없음
    
    ⇒ 내가 접근해야 하는 데이터인데 보호하면?
    
    하지만 세그먼테이션은 논리 영역으로 나누기 때문에 Code 영역 전체를 Read-only로 통제하면 보호할 수 있다
    
    </aside>
    
- 공유
    
    <aside>
    
    하나로 묶여있는 영역 다
    
    </aside>
    

단편화

- 외부
    
    ⇒ 서로 다른 크기의 segment들이 할당/삭제가 이뤄지면 외부 단편화가 발생한다
    
- 내부
    
    ⇒ 필요한 크기만큼 메모리를 할당하므로 내부 단편화 문제를 해결한다
    

## 8. 연속 할당

⇒ 프로세스를 메모리에 올릴 때 주소 공간을 메모리의 한 곳에 연속적으로 적재하는 방식

연속 할당은

- 고정분할 방식
- 가변분할 방식

2가지로 나뉜다

### 8.1 고정 분할 방식

⇒ 물리적 메모리를 정해진 개수만큼 영구적인 분할로 나누어두고 각 분할에 하나의 프로세스를 적재함

- 동시에 메모리에 올릴 수 있는 프로그램 수가 고정됨
- 수행 가능한 프로그램의 최대 크기가 제한됨
- 융통성이 떨어짐

### 8.2 가변 분할 방식

⇒ 메모리에 적재되는 프로그램의 크기에 따라 분할의 크기, 개수가 동적으로 변하는 방식

문제

어디 메모리 공간에 프로세스를 올려야 할지 결정해야 함

- 최초적합(First Fit): 가용 공간 중 가장 먼저 발견되는 곳에 바로 할당하는 방법
- 최적적합(Best Fit): 프로세스 크기와 가장 딱 맞는(남는 공간이 제일 적은) 공간을 찾아 할당하는 방법
- 최악적합(Worst Fit): 가장 여유 공간이 큰 곳에 프로세스를 할당하는 방법입니다. (남는 공간을 크게 만들어서 나중에 다른 프로세스가 쓰게 하려는 전략)